---
layout: post
title:  "교차언어 번역기 논문 리뷰"
---

다음 논문을 살펴본다.

[Zero-shot Cross-lingual Transfer of Neural Machine Translation with Multilingual Pretrained Encoders][paperlink]

[paperlink]: https://arxiv.org/abs/2104.08757

# Summary
<p align="center">
  <img src="https://github.com/user-attachments/assets/efca2ed3-179a-447c-a3df-68bb082d8cbd" width="50%" height="50%" alt="default" />
</p>

하나의 언어를 영어로 번역하는 것만 학습하고, 학습하지 않은 다른 언어를 번역할 수 있게 하는것이 논문의 핵심이다. 
Zero-shot learning은 학습할때 접하지 않은 데이터도 충분히 예측할 수 있게 만든다는 뜻이고, cross-lingual은 서로 다른 언어의 문장을 영어로 번역한다는 것이다.
이 논문은 사전에 학습된 인코더인 Multilingual pretrained encoder를 활용하여 뉴럴넷만 이용한 번역에 도전한다.

기존에도 여러 시도가 있었으나, 이 논문이 교차 언어 번역에서 기존의 다른 논문들의 성능을 월등하게 뛰어넘었다.
SixT라는 새로운 모델의 핵심은 'catastrophic forgetting'으로, 학습할때 언어의 디테일이나 잡다한 문법같은건 오버피팅되지 않게 다 잊어버리고, 언어의 본질적인 구조만 학습하게 하도록 했다는 점이다. 기술적으로는 각 인코더가 학습하는 첫 단계에서 썼던 ResNet구조의 residual connection을 두번째 단계에서는 제거하는 것이다. 이렇게 하면 위치제약을 완화시키는 효과가 있다. 

<br/>
<br/>
<br/>
    
# Discussion

<p align="center">
  <img src="https://github.com/user-attachments/assets/c965c2c6-916c-4c8a-9d49-d68ddabd07bd" width="80%" height="80%" alt="default" />
</p>

특히 덴마크어를 영어로 번역하는 것만 학습했음에도 한국어를 영어로 상당히 잘 번역한 것으로 보아 서로 다른 구조를 가지고 있는 언어체계더라도 공통된 특성이 있다는 것을 암시하는 것 같다. 
'혹시 새나 고래같은 다른 동물의 언어를 잘 인코딩 하면 이 교차번역기를 활용하여 영어로 번역할 수 있지 않을까?' 하는 생각이 들었다. 
하지만 다른 동물의 언어를 인코딩할 수 있는 인코더를 만드는 것도 아직 미해결 문제로 남아있다.
또한, 동물의 언어가 자신이 처한 상황(context)에 따라 같은 단어더라도 의미가 달라진다면 학습하기 어려울 것이다.
애초에 동물들의 언어가 영어나 다른 언어같이 단어의 조합으로 이루어져 있지 않을수도 있고, 이러한 차이점이 번역오류를 증가시킬 것이다.
그래도 고래의 언어번역은 연구가 이루어지고 있으니, 언젠가는 고래의 말을 이해할 수 있는 날이 오면 좋겠다.
