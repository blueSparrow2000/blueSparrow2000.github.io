---
layout: single # post
title: "DDPM"  # 페이지 타이틀
post-order: 4                               # (내 커스텀 변수) 같은 카테고리 내 정렬 순서
use_math: true
categories:
  - paperreview
---

[Denoising Diffusion Probabilistic Models][paperlink]

[paperlink]:https://arxiv.org/abs/2006.11239

위 논문을 살펴본다.

# preliminary
이전 게시물에 확산모델에 대한 전반적인 소개를 해두었다. DDPM은 초기 확산모델로, generic framework는 동일하다.

[Diffusion models][link]

[link]: https://bluesparrow2000.github.io/paperreview/diffusion/


# summary
확산 모델이 고품질 이미지를 생성하는데 사용할 수 있다는 것을 처음 보여준 논문이다.

확산 모델은 forward stage에서 여러 단계로 노이즈를 조금씩 추가하여 노이지 이미지로 만든다.
Reverse stage에서는 하나의 디노이징 (Unet을 기반으로 만든) 모델을 사용하여 각 단계마다 추가되었던 노이즈를 예측한다.

모델의 기본 구조는 self-attention layer를 추가한 Unet으로, 이미지에서 멀리 떨어져 있는 정보(feature)간의 관계를 학습하는데 용이하다.
또한 Transformer의 positional embedding을 추가하여 몇 번째 확산 단계인지를 모델이 알 수 있게 하였다.

*DDPM 구조 이미지

논문에 수식이 굉장히 많은데, 대부분이 아래의 손실함수를 유도하기 위한 과정이다.
Forward/reverse stage가 Markov process임을 이용하여 각 단계를 정의하고 손실함수를 만든다.

$$ \mathbb{E}_{q} [ D_{KL}( q(x_{T}|x_{0} ) || p( x_{T}) ) + \sum_{t>1} D_{KL}( q(x_{t-1}|x_{t},x_{0} ) || p_{\theta}( x_{t-1} | x_{t} ) ) - log{p_{\theta}( x_{0}|x_{1})}] $$ 

이 손실함수를 정리하여 학습하는데 사용할 수 있으나, 논문에서 제시한 간략화된 손실함수를 사용하는게 더 성능이 좋았다.

$$ L_{simple}(\theta} = \mathbb{E}_{t,x_{0},\epsilon} [ || \epsilon - \epsilon_{/theta} ( \sqrt{\overline{\alpha_{t}}}x_{0} + \sqrt{\overline{1 - \alpha_{t}}}\epsilon , t )     ||^2 ] $$



*progressive generation 사진
단계별로 노이즈를 제거하는 과정


<br/>

# discussion

확산모델에 의해 만들어진 잠재공간이 완전히 의미없는게 아니라는게 신기했다. 
논문에서 잠재공간에 있는 노이즈 두 개를 보간(interpolate)하고 reverse stage를 진행했더니 둘의 중간정도 되는 이미지를 생성하였다.
단순히 픽셀 단위로 두 이미지를 보간하면 이미지 manifold위에 있지 않은 부자연스러운 이미지가 된다. 반면 확산모델은 이미지 manifold를 학습하였기 때문에 모델을 통과하여 나온 이미지가 그럴싸하게 보인다. 

* 잠재구조에서 보간하는 이미지 메니폴드 설명 이미지 참조

확산 단계를 더 높이면 두 이미지와는 전혀 다른 새 이미지가 생성되었다. 잠재공간의 데이터가 어느정도 생성결과에 영향을 미치지만 확산단계가 높아질수록 영향이 희미해진다. 미세한 차이가 큰 차이를 만들어낸다는 것에서 카오스이론이 떠오른다.
