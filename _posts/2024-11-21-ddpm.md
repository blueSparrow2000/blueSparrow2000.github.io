---
layout: single # post
title: "DDPM"  # 페이지 타이틀
post-order: 4                               # (내 커스텀 변수) 같은 카테고리 내 정렬 순서
# comments: true
categories:
  - paperreview
---

다음 논문을 살펴본다.

[Denoising Diffusion Probabilistic Models][paperlink]

[paperlink]:https://arxiv.org/abs/2006.11239

# preliminary
이전 게시물에 확산모델에 대한 전반적인 소개를 해두었다. DDPM은 초기 확산모델로, generic framework는 동일하다.

[Diffusion models][link]

[link]: https://bluesparrow2000.github.io/paperreview/diffusion/


# summary
확산 모델이 고품질 이미지를 생성하는데 사용할 수 있다는 것을 처음 보여준 논문이다.

확산 모델은 forward stage에서 여러 단계로 노이즈를 조금씩 추가하여 노이지 이미지로 만든다고 했다.
Reverse stage에서는 이 노이지 이미지에 하나의 디노이징(Unet을 기반으로 만든) 모델을 사용하여 각 단계마다 추가되었던 노이즈를 예측한다.

모델의 기본 구조는 self-attention layer를 추가한 Unet으로, 이미지에서 멀리 떨어져 있는 정보(feature)간의 관계를 학습하는데 용이하다.
또한 Transformer의 positional embedding을 추가하여 몇 번째 확산 단계인지를 모델이 알 수 있게 하였다.




<br/>

# discussion

확산모델에 의해 만들어진 잠재공간이 완전히 의미없는게 아니라는게 신기했다. 
논문에서 잠재공간에 있는 노이즈 두 개를 보간(interpolate)하고 reverse stage를 진행했더니 둘의 중간정도 되는 이미지를 생성하였다.
확산 단계를 더 높이면 두 이미지와는 전혀 다른 새 이미지가 생성되었다. 잠재공간의 데이터가 어느정도 생성결과에 영향을 미치지만 확산단계가 높아질수록 영향이 희미해진다. 미세한 차이가 큰 차이를 만들어낸다는 것에서 카오스이론이 떠오른다.
