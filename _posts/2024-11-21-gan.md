---
layout: single # post
title: "GAN"  # 페이지 타이틀
post-order: 4                               # (내 커스텀 변수) 같은 카테고리 내 정렬 순서
# comments: true
categories:
  - paperreview
---

다음 논문을 살펴본다.

[Generative Adversarial Networks][paperlink]

[paperlink]:https://arxiv.org/abs/1406.2661

# summary
기존의 심층 신경망만 이용하는 방식으로는 진짜같은 이미지를 생성하기 어렵다. 
진짜같다의 기준을 간단한 손실함수로 만들 수 있겠는가?

GAN은 노이즈로부터 이미지를 생성하는 신경망과, 훈련 데이터인지 생성된 이미지인지 판별하는 신경망 두개를 이용하여 이 문제를 우회한다.
이 신경망들이 서로 대립한다는 의미에서 두 신경망을 adversarial network라고 한다. 여기에 생성모델이라는 의미를 붙여서 Generative Adversarial Network(GAN)이라고 한다.

생성자는 랜덤 노이즈(z)를 신경망을 거쳐 그럴싸한 이미지(G(z))로 만든다. 

판별자는 생성된 이미지와 훈련 이미지 중 랜덤하게 뽑아서, 이 이미지가 훈련 데이터에서 나왔을 확률을 계산한다.

판별자는 훈련 데이터를 올바르게 훈련 데이터라고 예측할 수 있어야 하고, 생성자는 생성된 데이터를 판별자가 훈련 데이터로 착가각하도록 속여야 한다. 즉 D(G(z))를 최대화 해야 한다.
이를 손실함수로 나타내면 다음과 같은 간단한 식으로 만들 수 있다.

V D G 함수 적기

이론대로모델이 수렴했을때, 생성자는 훈련 이미지 분포를 잘 학습한 상태이고, 판별자는 만들어진 이미지가 생성된건지 훈련 데이터인지 알 수 없으니 훈련 데이터라고 예측할 확률이 1/2이 된다.
논문에서 G
현실적으로 모델을 훈련시킬때 판별자를 


# discussion
GAN은 심플한 아이디어로도 빠르고 좋은 성능을 낼 수 있다는 점에서 매력적이다. 
그러나, generator와 discriminator가 골고루 학습되어야 한다는 치명적인 단점이 있다.
예를들어 생성자가 너무 진짜처럼 생성을 잘하는 반면 판별자가 학습이 덜 되었다고 하자. 판별자는 생성자가 만든 이미지를 대부분 진짜라고 판별할 것이고, 이로인해 생성자는 더이상 성능이 개선되지 않으며, 판별자도 마찬가지이다. 

이러한 문제점을 피하기 위한 방법들을 연구하면 안정적으로 GAN 모델을 사용할 수 있을 것이다.



