---
layout: single # post
title: "Diffusion Models"  # 페이지 타이틀
post-order: 4                               # (내 커스텀 변수) 같은 카테고리 내 정렬 순서
# comments: true
categories:
  - paperreview
---

요즘 유행하는 확산모델의 배경지식을 알아본다. 노이즈, 노이즈, 노이즈...

다음 논문을 참고하였다.

[Diffusion Models in Vision: A Survey][paperlink]

[paperlink]:https://arxiv.org/abs/2209.04747


# Diffusion 

* 확산과 노이즈 비교 이미지

한 곳에 모인 기체 분자가 확산하면 금방 사방으로 퍼져 처음 상태를 알기 힘들게 된다. 
처음 상태를 예측하기 위해서는 매 시간간격마다 한 입자가 어느 위치에서 이동했을지를 알아야 한다.
그러면 마지막 상태에서 차근차근 입자의 이동거리를 빼주면 처음 상태를 계산할 수 있다.

확산 모델도 이와 같은 방식으로 원본 이미지를 복원하도록 훈련받는다.
원래의 이미지에 노이즈를 조금씩 단계적으로 추가하면서 형체를 알아볼 수 없는 노이지 이미지(noisy image)로 만든다. 그리고 신경망을 이용해 각 단계에서 노이즈값(또는 분포)가 얼마였는지를 학습한다. 노이지 이미지에서 예측한 노이즈를 계속 빼주다 보면 원본 이미지를 복원할 수 있다!

이렇게 얻은 확산모델은 사용자가 원하는 명령을 바탕으로 특정 노이지 이미지를 주면 노이즈를 예측할 수 있다. 예측한 노이즈를 빼주면 사용자가 원하는 이미지가 나온다. 즉, 이미지를 생성하는데에도 사용할 수 있다.


# Model 
확산모델의 기본 구조는 다음과 같다.

* 모식도

노이지 이미지와 확산 단계(diffusion step) 정보를 입력으로 받아 노이즈를 예측한다.

정확도를 높이기 위해 확산 모델에 분류기(classifier)를 연결한 모델도 나왔다.
매 단계마다 확산 모델이 원하는 출력을 만들어낼 수 있도록 분류기가 gradient로 피드백 해주는 것이다.

multi modal 학습이 가능하도록 분류기 없이 학습하는 방법도 등장하였다.
텍스트로 피드백 해주는 모델인 GLIDE이다. 

* 글라이드 모식도

텍스트 정보는 트랜스포머가 처리하여 노이지 이미지와 함께 확산모델의 입력으로 들어간다.
확산모델이 작은 이미지를 생성하면, 또 다른 확산모델로 크게 확대시키는 구조이다. 
확산모델의 초창기에는 한번에 노이즈가 잘 제거된 큰 이미지를 만들어내지 못해 두 단계를 거쳤다.

그래도 수많은 이미지와 텍스트 정보를 같이 학습시키면, 그림에 대한 간략한 설명(캡션)과 노이즈 샘플만 주면 원하는 이미지를 생성해 낼 수 있다.


이를 개선하여 나온게 Latent Diffusion Model(LDM)이다.
인코더를 이용해 이미지를 잠재공간(latent space)으로 보낸 후 확산모델을 잠재공간에서 학습시킨다.
이렇게 하면 이미지를 픽셀 구조가 아닌 의미와 형태 단위로 파악할 수 있고 속도도 더 빠르다. 


# Theoretical background

